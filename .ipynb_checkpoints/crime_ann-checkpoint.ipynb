{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\rohit\\\\Downloads\\\\Book2.csv', parse_dates=['Dates'], index_col='Dates')\n",
    "#Renaming The columns\n",
    "fraud = data[data['Category'] == \"FRAUD\"]\n",
    "assault = data[data['Category'] == \"ASSAULT\"]\n",
    "FamilyOffenses = data[data['Category'] == \"FAMILY OFFENSES\"]\n",
    "OtherOffenses = data[data['Category'] == \"OTHER OFFENSES\"]\n",
    "vandalism = data[data['Category'] == \"VANDALISM\"]\n",
    "\n",
    "#indexing type here is by weeks\n",
    "data['DayOfWeek'] = data.index.dayofweek\n",
    "data['Hour'] = data.index.hour\n",
    "data['Month'] = data.index.month\n",
    "data['Year'] = data.index.year\n",
    "data['DayOfMonth'] = data.index.day\n",
    "\n",
    "#structure size\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "\n",
    "#use of library ggplot\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "daysOfWeekIdx = data.groupby('DayOfWeek').size().keys()\n",
    "daysOfWeekLit = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "occursByWeek = data.groupby('DayOfWeek').size().get_values()\n",
    "\n",
    "\n",
    "# Bar plot\n",
    "y = np.empty([6,7])\n",
    "h = [None]*6\n",
    "width = 0.1\n",
    "\n",
    "ax2 = plt.subplot2grid((3,3), (1,0), colspan=4)\n",
    "\n",
    "y[0] = fraud.groupby('DayOfWeek').size().get_values()\n",
    "y[1] = assault.groupby('DayOfWeek').size().get_values()\n",
    "y[2] = FamilyOffenses.groupby('DayOfWeek').size().get_values()\n",
    "y[3] = OtherOffenses.groupby('DayOfWeek').size().get_values()\n",
    "#y[4] = vandalism.groupby('DayOfWeek').size().get_values()\n",
    "\n",
    "\n",
    "color_sequence = ['#1f77b4', '#ff7f0e', '#2ca02c','#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "for i in range(0,5):\n",
    "    h[i] = ax2.bar(daysOfWeekIdx + i*width, y[i], width, color=color_sequence[i], alpha = 0.7)\n",
    "\n",
    "ax2.set_xticks(daysOfWeekIdx + 3*width)\n",
    "ax2.set_xticklabels(daysOfWeekLit)\n",
    "# ensure that ticks are only at the bottom and left parts of the plot\n",
    "ax2.get_xaxis().tick_bottom()\n",
    "ax2.get_yaxis().tick_left()\n",
    "\n",
    "ax2.legend((item[0] for item in h), \n",
    "           ('Fraud', 'Assault', 'Family Offenses', 'Other Offenses'), \n",
    "           bbox_to_anchor=(0.0, 1), loc=3, borderaxespad=0., frameon=False)\n",
    "\n",
    "\n",
    "plt.title('DayOfWeek wise occurence Crimes', fontsize = 28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "\n",
    "monthsIdx = data.groupby('Month').size().keys() - 1\n",
    "monthsLit = ['January', 'February', \n",
    "             'March', 'April', 'May', \n",
    "             'June', 'July','August', \n",
    "             'September', 'October', 'Novemeber', 'December']\n",
    "occursByMonth = data.groupby('Month').size().get_values()\n",
    "\n",
    "# Linear plot for all crimes\n",
    "ax1 = plt.subplot2grid((3,3), (0,0), colspan=3)\n",
    "ax1.plot(monthsIdx, occursByMonth, 'ro-', linewidth=2)\n",
    "\n",
    "ax1.set_title ('All Crimes', fontsize=20)\n",
    "\n",
    "start, end = ax1.get_xlim()\n",
    "ax1.xaxis.set_ticks(np.arange(start, end, 1))\n",
    "ax1.set_xticklabels(monthsLit)\n",
    "# ensure that ticks are only at the bottom and left parts of the plot\n",
    "ax1.get_xaxis().tick_bottom()\n",
    "ax1.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear normalized plot for 6 top crimes\n",
    "ax2 = plt.subplot2grid((3,3), (1,0), colspan=3, rowspan=2)\n",
    "\n",
    "y = np.empty([6,12])\n",
    "y[0] = fraud.groupby('Month').size().get_values()\n",
    "y[1] = assault.groupby('Month').size().get_values()\n",
    "y[2] = FamilyOffenses.groupby('Month').size().get_values()\n",
    "y[3] = OtherOffenses.groupby('Month').size().get_values()\n",
    "#y[4] = vandalism.groupby('Month').size().get_values()\n",
    "\n",
    "\n",
    "crimes = ['fraud', 'Assault', 'Family Offenses', 'Other Offenses']\n",
    "color_sequence = ['#1f77b4', '#ff7f0e', '#2ca02c','#d62728']\n",
    "\n",
    "for i in range(0,4):\n",
    "    y[i]= (y[i]-min(y[i]))/(max(y[i])-min(y[i]))  # normalization\n",
    "    h[i] = ax2.plot(monthsIdx, y[i],'o-', color=color_sequence[i], lw=2)\n",
    "\n",
    "ax2.set_ylabel(\"Crime occurences by month, normalized\")\n",
    "\n",
    "ax2.xaxis.set_ticks(np.arange(start, end+2, 1))\n",
    "ax2.set_xticklabels(monthsLit)\n",
    "\n",
    "ax2.legend((item[0] for item in h), \n",
    "           crimes, \n",
    "           bbox_to_anchor=(0.87, 1), loc=2, borderaxespad=0., frameon=False)\n",
    "\n",
    "pylab.gcf().text(0.5, 1.00, \n",
    "            'Month wise Occurence of Crimes',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='top', \n",
    "             fontsize = 28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re \n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "#reading the training data set\n",
    "SNF1 = pd.read_excel(\"C:\\\\Users\\\\rohit\\\\Downloads\\\\crime_and_day.xlsx\")\n",
    "SNF = SNF1.iloc[:, 0:7]\n",
    "y = SNF1.iloc[:,7:9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNF1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(SNF[[\"X\",\"Y\"]])\n",
    "SNF[[\"X\",\"Y\"]] = scaler.transform(SNF[[\"X\",\"Y\"]])\n",
    "SNF=SNF[abs(SNF[\"Y\"])<100]\n",
    "SNF.index=range(len(SNF))\n",
    "print(SNF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature normalization\n",
    "def normalize(data): \n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNF['X'] = normalize(SNF.X)\n",
    "SNF['Y'] = normalize(SNF.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SNF['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    DD=datetime.strptime(str(x),\"%Y-%m-%d %H:%M:%S\")\n",
    "    time=DD.hour\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time, day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting season : summer, fall, winter, spring from months column\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring\n",
    "\n",
    "#getting season : summer, fall, winter, spring from months column\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    feature_list=df.columns.tolist()\n",
    "    \n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print (\"Parsing dates...\")\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    \n",
    "    print (\"Creating season features...\")\n",
    "    cleanData[\"Summer\"], cleanData[\"Fall\"], cleanData[\"Winter\"], cleanData[\"Spring\"]=zip(*cleanData[\"Month\"].apply(get_season))\n",
    "    print(\"Creating Lat/Long feature...\")\n",
    "    xy_scaler = preprocessing.StandardScaler()\n",
    "    xy_scaler.fit(cleanData[[\"X\",\"Y\"]])\n",
    "    cleanData[[\"X\",\"Y\"]] = xy_scaler.transform(cleanData[[\"X\",\"Y\"]])\n",
    "    #set outliers to 0\n",
    "    cleanData[\"X\"]=cleanData[\"X\"].apply(lambda x: 0 if abs(x)>5 else x)\n",
    "    cleanData[\"Y\"]=cleanData[\"Y\"].apply(lambda y: 0 if abs(y)>5 else y)\n",
    "    print (\"Creating address features...\")\n",
    "    #recoding address as 0: if no interaction , 1: if interaction\n",
    "    cleanData[\"Addr\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    print (\"Creating dummy variables...\")\n",
    "    PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    #DAYOfWeek = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='WEEK')\n",
    "    TIME = pd.get_dummies(cleanData['Time'],prefix='HOUR')\n",
    "    Day = pd.get_dummies(cleanData['Day'],prefix='DAY')\n",
    "    Month = pd.get_dummies(cleanData['Month'],prefix='MONTH')\n",
    "    Year = pd.get_dummies(cleanData['Year'],prefix='YEAR')\n",
    "    \n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    \n",
    "    print (\"Joining features...\")\n",
    "    features = pd.concat([cleanData[feature_list],PD,TIME,Day,Month,Year],axis=1)\n",
    "    \n",
    "    print (\"Droping processed columns...\")\n",
    "    cleanFeatures=features.drop([\"PdDistrict\",\"Address\",\"Dates\",\"Time\",\"Day\",\"Month\",\"Year\"],\\\n",
    "                                axis=1,inplace=False)\n",
    "    \n",
    "    print('Done!')\n",
    "    \n",
    "    return cleanFeatures\n",
    "\n",
    "features = preprocess_data(SNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y[:, 1] = labelencoder.fit_transform(y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(features, test_size = 0.3, random_state = 0)\n",
    "y1_train, y1_test = train_test_split(y,test_size = 0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units =50, kernel_initializer = 'uniform', activation = 'relu', input_dim = 97))\n",
    "\n",
    "# Adding the second hidden layer clos\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "y1_test = y1_test.drop([10779])\n",
    "history = classifier.fit(X_train, y1_train, batch_size = 10, epochs = 60)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y1_test)\n",
    "ax.plot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
